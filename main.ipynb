{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![LogoUC3M](https://upload.wikimedia.org/wikipedia/commons/thumb/a/a6/Acr%C3%B3nimo_y_nombre_de_la_UC3M.svg/320px-Acr%C3%B3nimo_y_nombre_de_la_UC3M.svg.png) \n",
        "\n",
        "*Alonso Rios Guerra - 100495821 | Guillermo Sancho González - 100495991*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXynlq0Q41kQ"
      },
      "source": [
        "# *__Aprendizaje automático P1: Predicción del abandono de empleados__*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## *__Introducción__*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En esta práctica tenemos como objetivo desarrollar diferentes métodos de aprendizaje automático para predecir el abandono de los trabajadores de una empresa.\n",
        "\n",
        "Primero de todo empezaremos leyendo los datos que nos proporciona la empresa. En nuestro caso, usaremos el dataset Nº10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sTFn1Cbi41kR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "data_path = 'attrition_availabledata_10.csv.gz'\n",
        "\n",
        "data = pd.read_csv(data_path, compression='gzip', sep = ',')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## *__EDA Simplificado__*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Un EDA es una análisis exploratorio de datos, para organizar los datos, entender su contenido, entender cual son las variables más relevantes y cómo se relacionan unas con otras, determinar qué hacer con los datos faltantes y con los datos atípicos, y finalmente extraer conclusiones acerca de todo este análisis.\n",
        "\n",
        "Para hacer un eda debemos responder a distintas preguntas:\n",
        "\n",
        "-   ¿Cuántas instancias y atributos hay?\n",
        "\n",
        "-   ¿Qué tipo de atributos hay (numéricos o categóricos)? Esto se hace para verificar si hay características categóricas que deben ser codificadas (como variables dummy o one-hot encoding). Comprobar si hay variables categóricas con alta cardinalidad.\n",
        "\n",
        "-   ¿Qué atributos tienen valores faltantes y cuántos?\n",
        "\n",
        "-   ¿Existen columnas constantes o ID?\n",
        "\n",
        "-   ¿Es un problema de clasificación o regresión (variable de respuesta) y? En caso de clasificación, ¿las clases están desbalanceadas?\n",
        "\n",
        "A continuación le damos respuesta:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   ¿Cuántas instancias y atributos hay?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "La forma de la tabla es:\n",
            "===============================\n",
            "(2940, 31)\n"
          ]
        }
      ],
      "source": [
        "print('La forma de la tabla es:')\n",
        "print('===============================')\n",
        "print(data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El dataset contiene 2940 instancias, 30 atributos y 1 etiqueta (Attrition)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   ¿Qué tipo de atributos hay (numéricos o categóricos)? Esto se hace para verificar si hay características categóricas que deben ser codificadas (como variables dummy o one-hot encoding). Comprobar si hay variables categóricas con alta cardinalidad."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Los tipos de atributos son:\n",
            "================================\n",
            "hrs                        float64\n",
            "absences                     int64\n",
            "JobInvolvement               int64\n",
            "PerformanceRating            int64\n",
            "EnvironmentSatisfaction    float64\n",
            "JobSatisfaction            float64\n",
            "WorkLifeBalance            float64\n",
            "Age                          int64\n",
            "BusinessTravel              object\n",
            "Department                  object\n",
            "DistanceFromHome             int64\n",
            "Education                    int64\n",
            "EducationField              object\n",
            "EmployeeCount                int64\n",
            "EmployeeID                   int64\n",
            "Gender                      object\n",
            "JobLevel                     int64\n",
            "JobRole                     object\n",
            "MaritalStatus               object\n",
            "MonthlyIncome                int64\n",
            "NumCompaniesWorked         float64\n",
            "Over18                      object\n",
            "PercentSalaryHike            int64\n",
            "StandardHours                int64\n",
            "StockOptionLevel             int64\n",
            "TotalWorkingYears          float64\n",
            "TrainingTimesLastYear        int64\n",
            "YearsAtCompany               int64\n",
            "YearsSinceLastPromotion      int64\n",
            "YearsWithCurrManager         int64\n",
            "Attrition                   object\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "print('Los tipos de atributos son:')\n",
        "print('================================')\n",
        "print(data.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Existen dos tipos de atributos en nuestro dataset: numéricos y categóricos. Dentro de los numéricos encontramos de tipo entero (absences, Age, JobLevel, ...) y de tipo float (hrs, TotalWorkingYears, JobSatisfaction). En cuanto a lo atributos categóricos encontramos algunos como Department, JobRole, MaritalStatus, ... Para entrenar a nuestro modelo nos interesa codificar las variables categóricas y por ello es importante ver como de viable es según su cardinalidad."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cardinalidad de los atributos categóricos:\n",
            "================================\n",
            "BusinessTravel: 3 categorías únicas\n",
            "Department: 3 categorías únicas\n",
            "EducationField: 6 categorías únicas\n",
            "Gender: 2 categorías únicas\n",
            "JobRole: 9 categorías únicas\n",
            "MaritalStatus: 3 categorías únicas\n",
            "Attrition: 2 categorías únicas\n"
          ]
        }
      ],
      "source": [
        "columnas_cat = data.select_dtypes(include=['object']).columns # Selecciona las columnas categóricas\n",
        "\n",
        "print('Cardinalidad de los atributos categóricos:')\n",
        "print('================================')\n",
        "for col in columnas_cat: # Imprime la cardinalidad de cada atributo categórico\n",
        "    print(f\"{col}: {data[col].nunique()} categorías únicas\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Al observar la ejecución del código anterior vemos que la cardinalidad de nuestros atributos categóricos es baja, en un rango de [2-9], y por ello no implicará ningún problema a la hora realizar una codificación dummy o One-Hot Encoding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   ¿Qué atributos tienen valores faltantes y cuántos?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cuántos valores faltan por atributo:\n",
            "======================================\n",
            "EnvironmentSatisfaction    15\n",
            "JobSatisfaction            12\n",
            "WorkLifeBalance            29\n",
            "NumCompaniesWorked         17\n",
            "TotalWorkingYears           5\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print('Cuántos valores faltan por atributo:')\n",
        "print('======================================')\n",
        "sin_valor = data.isnull().sum()  # Cuenta valores nulos por columna\n",
        "sin_valor = sin_valor[sin_valor > 0]  # Filtra solo los que tienen valores nulos\n",
        "\n",
        "print(sin_valor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tras ejecutar el código anterior, obtenemos que existen 5 atributos con valores faltantes. Estos atributos son: \n",
        "EnvironmentSatisfaction con 15 faltantes, \n",
        "JobSatisfaction con 12 faltantes,\n",
        "WorkLifeBalance con 29 faltantes,\n",
        "NumCompaniesWorked con 17 faltantes y\n",
        "TotalWorkingYears con 5 faltantes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- ¿Existen columnas constantes o ID?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columnas constantes: ['EmployeeCount', 'Over18', 'StandardHours']\n",
            "Columnas ID: ['EmployeeID']\n"
          ]
        }
      ],
      "source": [
        "# 1. Comprobar columnas constantes\n",
        "constantes = [col for col in data.columns if data[col].nunique() == 1]\n",
        "print(\"Columnas constantes:\", constantes)\n",
        "\n",
        "# 2. Comprobar columnas ID\n",
        "columnas_id = [col for col in data.columns if data[col].nunique() == len(data)]\n",
        "print(\"Columnas ID:\", columnas_id)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observamos que existen 3 columnas constantes (EmployeeCount, Over18, StandardHours) y una columna ID (EmployeeID)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- ¿Es un problema de clasificación o regresión (variable de respuesta) y? En caso de clasificación, ¿las clases están desbalanceadas?\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En este caso es fácil ver que es un problema de __clasificación__ porque la etiqueta (Attrition) en los datos train solo pueden tener valores 'Yes' o 'No', por lo que es una clase binaria."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Comprobar si la clase está desbalanceada:\n",
            "======================================\n",
            "Attrition\n",
            "No     2466\n",
            "Yes     474\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Attrition\n",
            "No     0.838776\n",
            "Yes    0.161224\n",
            "Name: count, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print('Comprobar si la clase está desbalanceada:')\n",
        "print('======================================')\n",
        "print(data['Attrition'].value_counts())\n",
        "print()\n",
        "print(data['Attrition'].value_counts() / data['Attrition'].count())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se puede ver que la clase esta bastante desbalanceada: 83.88% No, 16.12% Yes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## *__¿Cómo se va a realizar la evaluación?__*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## *__Metodos básicos: KNN y Tree__*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Inicialmente vamos a eliminar las columnas constantes o ids que consideramos que no aportan información a la investigación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = data.drop(columns=constantes + columnas_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Despues, se dividen los datos en x e y, donde x son los inputs, e y es la etiqueta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X = data.drop(columns=['Attrition'])\n",
        "y = data['Attrition']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- 1.- KNN con hiperparametros default, scaler standard y como imputación la media"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model score: 0.844\n",
            "Model score: 0.841\n",
            "Model score: 0.839\n",
            "Model score: 0.845\n",
            "Model score: 0.841\n",
            "Model score: 0.838\n"
          ]
        }
      ],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler, RobustScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "#Separar variables categoricas y numéricas\n",
        "columnas_num = X.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
        "columnas_cat = X.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "scalers = [StandardScaler(), MinMaxScaler(), RobustScaler()]\n",
        "imputers = [SimpleImputer(strategy='mean'), SimpleImputer(strategy='median')]\n",
        "\n",
        "#Definir los pasos en la Pipeline\n",
        "for i in range(len(imputers)):\n",
        "    for j in range(len(scalers)):\n",
        "        knn = KNeighborsClassifier()\n",
        "        scaler = scalers[j]\n",
        "        imputer = imputers[i]\n",
        "        encoder = OneHotEncoder()\n",
        "\n",
        "        classif_numericos = Pipeline([\n",
        "            (\"imputation\", imputer),\n",
        "            (\"standardization\", scaler)\n",
        "        ])\n",
        "\n",
        "        classif_categoricos = Pipeline([\n",
        "            (\"encoder\", encoder),\n",
        "            (\"imputation\", imputer)\n",
        "        ])\n",
        "\n",
        "        preprocessor = ColumnTransformer(\n",
        "            transformers=[\n",
        "                (\"num\", classif_numericos, columnas_num),\n",
        "                (\"cat\", classif_categoricos, columnas_cat)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        clf = Pipeline([(\"preprocessor\", preprocessor), (\"classifier\", knn)])\n",
        "\n",
        "        clf.fit(X_train, y_train)\n",
        "        print(\"Model score: %.3f\" % clf.score(X_test, y_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El mejor valor obtenido es el cuarto: standard scaler, median imputer"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
