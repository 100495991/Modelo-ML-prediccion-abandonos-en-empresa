{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![LogoUC3M](https://upload.wikimedia.org/wikipedia/commons/thumb/a/a6/Acr%C3%B3nimo_y_nombre_de_la_UC3M.svg/320px-Acr%C3%B3nimo_y_nombre_de_la_UC3M.svg.png) \n",
        "\n",
        "*Alonso Rios Guerra - 100495821 | Guillermo Sancho González - 100495991*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXynlq0Q41kQ"
      },
      "source": [
        "# *__Aprendizaje automático P1: Predicción del abandono de empleados__*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## *__1. Introducción__*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En esta práctica tenemos como objetivo desarrollar diferentes métodos de aprendizaje automático para predecir el abandono de los trabajadores de una empresa.\n",
        "\n",
        "Primero de todo empezaremos leyendo los datos que nos proporciona la empresa. En nuestro caso, usaremos el dataset Nº10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sTFn1Cbi41kR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "data_path = 'attrition_availabledata_10.csv.gz'\n",
        "\n",
        "data = pd.read_csv(data_path, compression='gzip', sep = ',')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## *__2. EDA Simplificado__*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Un EDA es una análisis exploratorio de datos, para organizar los datos, entender su contenido, entender cual son las variables más relevantes y cómo se relacionan unas con otras, determinar qué hacer con los datos faltantes y con los datos atípicos, y finalmente extraer conclusiones acerca de todo este análisis.\n",
        "\n",
        "Para hacer un eda debemos responder a distintas preguntas:\n",
        "\n",
        "-   ¿Cuántas instancias y atributos hay?\n",
        "\n",
        "-   ¿Qué tipo de atributos hay (numéricos o categóricos)? Esto se hace para verificar si hay características categóricas que deben ser codificadas (como variables dummy o one-hot encoding). Comprobar si hay variables categóricas con alta cardinalidad.\n",
        "\n",
        "-   ¿Qué atributos tienen valores faltantes y cuántos?\n",
        "\n",
        "-   ¿Existen columnas constantes o ID?\n",
        "\n",
        "-   ¿Es un problema de clasificación o regresión (variable de respuesta) y? En caso de clasificación, ¿las clases están desbalanceadas?\n",
        "\n",
        "A continuación le damos respuesta:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   ¿Cuántas instancias y atributos hay?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "La forma de la tabla es: (2940, 27)\n"
          ]
        }
      ],
      "source": [
        "print('La forma de la tabla es:', data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El dataset contiene 2940 instancias, 30 atributos y 1 etiqueta (Attrition)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   ¿Qué tipo de atributos hay (numéricos o categóricos)? Esto se hace para verificar si hay características categóricas que deben ser codificadas (como variables dummy o one-hot encoding). Comprobar si hay variables categóricas con alta cardinalidad."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Los tipos de atributos son:\n",
            "==================================\n",
            "hrs                        float64\n",
            "absences                     int64\n",
            "JobInvolvement               int64\n",
            "PerformanceRating            int64\n",
            "EnvironmentSatisfaction    float64\n",
            "JobSatisfaction            float64\n",
            "WorkLifeBalance            float64\n",
            "Age                          int64\n",
            "BusinessTravel              object\n",
            "Department                  object\n",
            "DistanceFromHome             int64\n",
            "Education                    int64\n",
            "EducationField              object\n",
            "Gender                      object\n",
            "JobLevel                     int64\n",
            "JobRole                     object\n",
            "MaritalStatus               object\n",
            "MonthlyIncome                int64\n",
            "NumCompaniesWorked         float64\n",
            "PercentSalaryHike            int64\n",
            "StockOptionLevel             int64\n",
            "TotalWorkingYears          float64\n",
            "TrainingTimesLastYear        int64\n",
            "YearsAtCompany               int64\n",
            "YearsSinceLastPromotion      int64\n",
            "YearsWithCurrManager         int64\n",
            "Attrition                   object\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "print('Los tipos de atributos son:')\n",
        "print('==================================')\n",
        "print(data.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Existen dos tipos de atributos en nuestro dataset: numéricos y categóricos. Dentro de los numéricos encontramos de tipo entero (absences, Age, JobLevel, ...) y de tipo float (hrs, TotalWorkingYears, JobSatisfaction). En cuanto a lo atributos categóricos encontramos algunos como Department, JobRole, MaritalStatus, ... Para entrenar a nuestro modelo nos interesa codificar las variables categóricas y por ello es importante ver como de viable es según su cardinalidad."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cardinalidad de los atributos categóricos:\n",
            "================================\n",
            "BusinessTravel: 3 categorías únicas\n",
            "Department: 3 categorías únicas\n",
            "EducationField: 6 categorías únicas\n",
            "Gender: 2 categorías únicas\n",
            "JobRole: 9 categorías únicas\n",
            "MaritalStatus: 3 categorías únicas\n",
            "Over18: 1 categorías únicas\n",
            "Attrition: 2 categorías únicas\n"
          ]
        }
      ],
      "source": [
        "columnas_cat = data.select_dtypes(include=['object']).columns # Selecciona las columnas categóricas\n",
        "\n",
        "print('Cardinalidad de los atributos categóricos:')\n",
        "print('================================')\n",
        "for col in columnas_cat: # Imprime la cardinalidad de cada atributo categórico\n",
        "    print(f\"{col}: {data[col].nunique()} categorías únicas\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Al observar la ejecución del código anterior vemos que la cardinalidad de nuestros atributos categóricos es baja, en un rango de [2-9], y por ello no implicará ningún problema a la hora realizar una codificación dummy o One-Hot Encoding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   ¿Qué atributos tienen valores faltantes y cuántos?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cuántos valores faltan por atributo:\n",
            "====================================\n",
            "EnvironmentSatisfaction    15\n",
            "JobSatisfaction            12\n",
            "WorkLifeBalance            29\n",
            "NumCompaniesWorked         17\n",
            "TotalWorkingYears           5\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print('Cuántos valores faltan por atributo:')\n",
        "print('====================================')\n",
        "sin_valor = data.isnull().sum()  # Cuenta valores nulos por columna\n",
        "sin_valor = sin_valor[sin_valor > 0]  # Filtra solo los que tienen valores nulos\n",
        "\n",
        "print(sin_valor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tras ejecutar el código anterior, obtenemos que existen 5 atributos con valores faltantes. Estos atributos son: \n",
        "EnvironmentSatisfaction con 15 faltantes, \n",
        "JobSatisfaction con 12 faltantes,\n",
        "WorkLifeBalance con 29 faltantes,\n",
        "NumCompaniesWorked con 17 faltantes y\n",
        "TotalWorkingYears con 5 faltantes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- ¿Existen columnas constantes o ID?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columnas constantes: ['EmployeeCount', 'Over18', 'StandardHours']\n",
            "Columnas ID: ['EmployeeID']\n"
          ]
        }
      ],
      "source": [
        "# 1. Comprobar columnas constantes\n",
        "constantes = [col for col in data.columns if data[col].nunique() == 1]\n",
        "print(\"Columnas constantes:\", constantes)\n",
        "\n",
        "# 2. Comprobar columnas ID\n",
        "columnas_id = [col for col in data.columns if data[col].nunique() == len(data)]\n",
        "print(\"Columnas ID:\", columnas_id)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observamos que existen 3 columnas constantes (EmployeeCount, Over18, StandardHours) y una columna ID (EmployeeID)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- ¿Es un problema de clasificación o regresión (variable de respuesta) y? En caso de clasificación, ¿las clases están desbalanceadas?\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En este caso es fácil ver que es un problema de __clasificación__ porque la etiqueta (Attrition) en los datos train solo pueden tener valores 'Yes' o 'No', por lo que es una clase binaria."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Comprobar si la clase está desbalanceada:\n",
            "======================================\n",
            "Attrition\n",
            "No     2466\n",
            "Yes     474\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Attrition\n",
            "No     0.838776\n",
            "Yes    0.161224\n",
            "Name: count, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print('Comprobar si la clase está desbalanceada:')\n",
        "print('======================================')\n",
        "print(data['Attrition'].value_counts())\n",
        "print()\n",
        "print(data['Attrition'].value_counts() / data['Attrition'].count())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se puede ver que la clase esta bastante desbalanceada: 83.88% No, 16.12% Yes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## *__3. ¿Cómo se va a realizar la evaluación?__*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para realizar la evaluación de nuestro modelo vamos a seguir una serie de pasos. La evaluación estará divida en inner, donde se elegirá el mejor scaler, imputer y ajuste de hiperparámetros, y outer, donde se estimará el rendimiento a futuro del modelo. Es importante dividir nuestro dataset en datos de entrenamiento (usados en inner) y de validación (usados en outer). En nuestro caso seguiremos el Holdout ((2/3) Train y (1/3) Test).\n",
        "\n",
        "- Inner Evaluation\n",
        "\n",
        "    - Primero\n",
        "\n",
        "- Outer Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## *__4. Metodos básicos: KNN y Tree__*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Inicialmente vamos a eliminar las columnas constantes o ids que consideramos que no aportan información a la investigación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = data.drop(columns=constantes + columnas_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se dividen los datos en x e y, donde x son los inputs, e y es la etiqueta.\n",
        "\n",
        "Despues se vuelven a dividir en train y en test. Train se usará para la evaluación interna, y test se usará para la evaluación final.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X = data.drop(columns=['Attrition'])\n",
        "y = data['Attrition']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se itera creando pipelines con los distintos imputers y scalers para observar cual es el que tiene más precisión en el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8505102040816326\n",
            "0.8367346938775511\n",
            "0.8535714285714286\n",
            "0.8505102040816326\n",
            "0.8362244897959183\n",
            "0.8540816326530614\n",
            "Best accuracy: 0.8541. With scaler: RobustScaler(), imputer: median\n"
          ]
        }
      ],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler, RobustScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn import metrics\n",
        "\n",
        "#Separar variables categoricas y numéricas\n",
        "columnas_num = X.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
        "columnas_cat = X.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "\n",
        "#Distintos métodos de escalado e imputación\n",
        "scalers = [StandardScaler(), MinMaxScaler(), RobustScaler()]\n",
        "imputers = ['mean', 'median']\n",
        "\n",
        "#Se realiza una crossvalidation con 3 folds\n",
        "cv = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "accuracy = -np.inf\n",
        "best_scaler, best_imputer = None, None\n",
        "\n",
        "#Definir los pasos en la Pipeline\n",
        "for i in range(len(imputers)):\n",
        "    for j in range(len(scalers)):\n",
        "        knn = KNeighborsClassifier()\n",
        "        scaler = scalers[j]\n",
        "        imputer = SimpleImputer(strategy=imputers[i])\n",
        "        encoder = OneHotEncoder()\n",
        "\n",
        "        classif_numericos = Pipeline([\n",
        "            (\"imputation\", imputer),\n",
        "            (\"standardization\", scaler)\n",
        "        ])\n",
        "\n",
        "        classif_categoricos = Pipeline([\n",
        "            (\"encoder\", encoder),\n",
        "            (\"imputation\", imputer)\n",
        "        ])\n",
        "\n",
        "        preprocessor = ColumnTransformer(\n",
        "            transformers=[\n",
        "                (\"num\", classif_numericos, columnas_num),\n",
        "                (\"cat\", classif_categoricos, columnas_cat)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        clf = Pipeline([(\"preprocessor\", preprocessor), (\"knn\", knn)])\n",
        "\n",
        "        scores = cross_val_score(clf, X_train, y_train, scoring='accuracy', cv=cv)\n",
        "        print(scores.mean())\n",
        "        if scores.mean() > accuracy:\n",
        "            accuracy = scores.mean()\n",
        "            best_scaler, best_imputer = scalers[j], imputers[i]\n",
        "        \"\"\"print(f\"La precisión media de la validación cruzada es: {scores.mean():.4f} ± {scores.std():.4f}\")\"\"\"\n",
        "\n",
        "print(f\"Best accuracy: {accuracy:.4f}. With scaler: {best_scaler}, imputer: {best_imputer}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El mejor scaler es el StandardScaler(), y el mejor imputer el SimpleImputer(strategy='mean'), es decir, utilizando la media para imputar los datos nulos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Una vez sabemos cual es el mejor scaler y el mejor imputer, hacemos el mismo proceso hecho antes, pero para elegir los mejores hiperparámetros del KNN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best accuracy: 0.8969. With n: 1, p: 2\n"
          ]
        }
      ],
      "source": [
        "classif_numericos = Pipeline([\n",
        "    (\"imputation\", SimpleImputer(strategy=best_imputer)),\n",
        "    (\"standardization\", best_scaler)\n",
        "])\n",
        "\n",
        "classif_categoricos = Pipeline([\n",
        "    (\"encoder\", OneHotEncoder()),\n",
        "    (\"imputation\", SimpleImputer(strategy=best_imputer))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", classif_numericos, columnas_num),\n",
        "        (\"cat\", classif_categoricos, columnas_cat)\n",
        "    ]\n",
        ")\n",
        "accuracy = -np.inf\n",
        "best_n, best_p = 0, 0\n",
        "\n",
        "for n in [1, 2, 3, 4, 8, 16, 32]: # Elegir el numero de neighbors\n",
        "    for p in [1, 2]: # Usar la distancia de Manhattan (1) o Euclídea\n",
        "\n",
        "        clf = Pipeline([(\"preprocessor\", preprocessor), (\"classifier\", KNeighborsClassifier(p=p, n_neighbors=n))])\n",
        "        \n",
        "        scores = cross_val_score(clf, X_train, y_train, scoring='accuracy', cv=cv)\n",
        "        if scores.mean() > accuracy:\n",
        "            accuracy = scores.mean()\n",
        "            best_n, best_p = n, p\n",
        "\n",
        "print(f\"Best accuracy: {accuracy:.4f}. With n: {best_n}, p: {best_p}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Los hiperparámetros optimizados obtenidos son que el valor de K (n-neighbors) sea 1 y se utilize la distancia euclídea (p=2), con una precisión de 0,8969."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
