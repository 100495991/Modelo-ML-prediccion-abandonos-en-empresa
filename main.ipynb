{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![LogoUC3M](https://upload.wikimedia.org/wikipedia/commons/thumb/a/a6/Acr%C3%B3nimo_y_nombre_de_la_UC3M.svg/320px-Acr%C3%B3nimo_y_nombre_de_la_UC3M.svg.png) \n",
        "\n",
        "*Alonso Rios Guerra - 100495821 | Guillermo Sancho González - 100495991*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXynlq0Q41kQ"
      },
      "source": [
        "# *__Aprendizaje automático P1: Predicción del abandono de empleados__*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## *__Introducción__*\n",
        "\n",
        "En esta práctica tenemos como objetivo desarrollar diferentes métodos de aprendizaje automático para predecir el abandono de los trabajadores de una empresa.\n",
        "\n",
        "Primero de todo empezaremos leyendo los datos que nos proporciona la empresa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "sTFn1Cbi41kR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "data_path = 'attrition_availabledata_10.csv.gz'\n",
        "\n",
        "data = pd.read_csv(data_path, compression='gzip', sep = ',')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## *__EDA Simplificado__*\n",
        "\n",
        "Un EDA es una análisis exploratorio de datos, para organizar los datos, entender su contenido, entender cual son las variables más relevantes y cómo se relacionan unas con otras, determinar qué hacer con los datos faltantes y con los datos atípicos, y finalmente extraer conclusiones acerca de todo este análisis.\n",
        "\n",
        "Para hacer un eda debemos responder a distintas preguntas:\n",
        "\n",
        "-   ¿Cuántas instancias y atributos hay?\n",
        "\n",
        "-   ¿Qué tipo de atributos hay (numéricos o categóricos)? Esto se hace para verificar si hay características categóricas que deben ser codificadas (como variables dummy o one-hot encoding). Comprobar si hay variables categóricas con alta cardenalidad.\n",
        "\n",
        "-   ¿Qué atributos tienen valores faltantes y cuántos?\n",
        "\n",
        "-   ¿Existen columnas constantes o ID?\n",
        "\n",
        "-   ¿Es un problema de clasificación o regresión (variable de respuesta) y? En caso de clasificación, ¿las clases están desbalanceadas?\n",
        "\n",
        "A continuación le damos respuesta:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   ¿Cuántas instancias y atributos hay?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "La forma de la tabla es:\n",
            "===============================\n",
            "(2940, 31)\n"
          ]
        }
      ],
      "source": [
        "print('La forma de la tabla es:')\n",
        "print('===============================')\n",
        "print(data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El dataset contiene 2940 instancias, 30 atributos y 1 etiqueta (Attrition)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   ¿Qué tipo de atributos hay (numéricos o categóricos)? Esto se hace para verificar si hay características categóricas que deben ser codificadas (como variables dummy o one-hot encoding). Comprobar si hay variables categóricas con alta cardenalidad."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Los tipos de atributos son:\n",
            "================================\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2940 entries, 0 to 2939\n",
            "Data columns (total 31 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   hrs                      2940 non-null   float64\n",
            " 1   absences                 2940 non-null   int64  \n",
            " 2   JobInvolvement           2940 non-null   int64  \n",
            " 3   PerformanceRating        2940 non-null   int64  \n",
            " 4   EnvironmentSatisfaction  2925 non-null   float64\n",
            " 5   JobSatisfaction          2928 non-null   float64\n",
            " 6   WorkLifeBalance          2911 non-null   float64\n",
            " 7   Age                      2940 non-null   int64  \n",
            " 8   BusinessTravel           2940 non-null   object \n",
            " 9   Department               2940 non-null   object \n",
            " 10  DistanceFromHome         2940 non-null   int64  \n",
            " 11  Education                2940 non-null   int64  \n",
            " 12  EducationField           2940 non-null   object \n",
            " 13  EmployeeCount            2940 non-null   int64  \n",
            " 14  EmployeeID               2940 non-null   int64  \n",
            " 15  Gender                   2940 non-null   object \n",
            " 16  JobLevel                 2940 non-null   int64  \n",
            " 17  JobRole                  2940 non-null   object \n",
            " 18  MaritalStatus            2940 non-null   object \n",
            " 19  MonthlyIncome            2940 non-null   int64  \n",
            " 20  NumCompaniesWorked       2923 non-null   float64\n",
            " 21  Over18                   2940 non-null   object \n",
            " 22  PercentSalaryHike        2940 non-null   int64  \n",
            " 23  StandardHours            2940 non-null   int64  \n",
            " 24  StockOptionLevel         2940 non-null   int64  \n",
            " 25  TotalWorkingYears        2935 non-null   float64\n",
            " 26  TrainingTimesLastYear    2940 non-null   int64  \n",
            " 27  YearsAtCompany           2940 non-null   int64  \n",
            " 28  YearsSinceLastPromotion  2940 non-null   int64  \n",
            " 29  YearsWithCurrManager     2940 non-null   int64  \n",
            " 30  Attrition                2940 non-null   object \n",
            "dtypes: float64(6), int64(17), object(8)\n",
            "memory usage: 712.2+ KB\n"
          ]
        }
      ],
      "source": [
        "print('Los tipos de atributos son:')\n",
        "print('================================')\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Los tipos de atributos son:\n",
            "================================\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2940 entries, 0 to 2939\n",
            "Data columns (total 31 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   hrs                      2940 non-null   float64\n",
            " 1   absences                 2940 non-null   int64  \n",
            " 2   JobInvolvement           2940 non-null   int64  \n",
            " 3   PerformanceRating        2940 non-null   int64  \n",
            " 4   EnvironmentSatisfaction  2925 non-null   float64\n",
            " 5   JobSatisfaction          2928 non-null   float64\n",
            " 6   WorkLifeBalance          2911 non-null   float64\n",
            " 7   Age                      2940 non-null   int64  \n",
            " 8   BusinessTravel           2940 non-null   object \n",
            " 9   Department               2940 non-null   object \n",
            " 10  DistanceFromHome         2940 non-null   int64  \n",
            " 11  Education                2940 non-null   int64  \n",
            " 12  EducationField           2940 non-null   object \n",
            " 13  EmployeeCount            2940 non-null   int64  \n",
            " 14  EmployeeID               2940 non-null   int64  \n",
            " 15  Gender                   2940 non-null   object \n",
            " 16  JobLevel                 2940 non-null   int64  \n",
            " 17  JobRole                  2940 non-null   object \n",
            " 18  MaritalStatus            2940 non-null   object \n",
            " 19  MonthlyIncome            2940 non-null   int64  \n",
            " 20  NumCompaniesWorked       2923 non-null   float64\n",
            " 21  Over18                   2940 non-null   object \n",
            " 22  PercentSalaryHike        2940 non-null   int64  \n",
            " 23  StandardHours            2940 non-null   int64  \n",
            " 24  StockOptionLevel         2940 non-null   int64  \n",
            " 25  TotalWorkingYears        2935 non-null   float64\n",
            " 26  TrainingTimesLastYear    2940 non-null   int64  \n",
            " 27  YearsAtCompany           2940 non-null   int64  \n",
            " 28  YearsSinceLastPromotion  2940 non-null   int64  \n",
            " 29  YearsWithCurrManager     2940 non-null   int64  \n",
            " 30  Attrition                2940 non-null   object \n",
            "dtypes: float64(6), int64(17), object(8)\n",
            "memory usage: 712.2+ KB\n",
            "\n",
            "Cuantos valores faltan por atributo:\n",
            "======================================\n",
            "hrs                         0\n",
            "absences                    0\n",
            "JobInvolvement              0\n",
            "PerformanceRating           0\n",
            "EnvironmentSatisfaction    15\n",
            "JobSatisfaction            12\n",
            "WorkLifeBalance            29\n",
            "Age                         0\n",
            "BusinessTravel              0\n",
            "Department                  0\n",
            "DistanceFromHome            0\n",
            "Education                   0\n",
            "EducationField              0\n",
            "EmployeeCount               0\n",
            "EmployeeID                  0\n",
            "Gender                      0\n",
            "JobLevel                    0\n",
            "JobRole                     0\n",
            "MaritalStatus               0\n",
            "MonthlyIncome               0\n",
            "NumCompaniesWorked         17\n",
            "Over18                      0\n",
            "PercentSalaryHike           0\n",
            "StandardHours               0\n",
            "StockOptionLevel            0\n",
            "TotalWorkingYears           5\n",
            "TrainingTimesLastYear       0\n",
            "YearsAtCompany              0\n",
            "YearsSinceLastPromotion     0\n",
            "YearsWithCurrManager        0\n",
            "Attrition                   0\n",
            "dtype: int64\n",
            "\n",
            "Comprobar si la clase está desbalanceada:\n",
            "======================================\n",
            "Attrition\n",
            "No     2466\n",
            "Yes     474\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Attrition\n",
            "No     0.838776\n",
            "Yes    0.161224\n",
            "Name: count, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print('Los tipos de atributos son:')\n",
        "print('================================')\n",
        "data.info()\n",
        "\n",
        "print()\n",
        "\n",
        "print('Cuantos valores faltan por atributo:')\n",
        "print('======================================')\n",
        "print(data.isnull().sum())\n",
        "\n",
        "print()\n",
        "\n",
        "print('Comprobar si la clase está desbalanceada:')\n",
        "print('======================================')\n",
        "print(data['Attrition'].value_counts())\n",
        "print()\n",
        "print(data['Attrition'].value_counts() / data['Attrition'].count())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La etiqueta es Attrition, que puede tener los valores Yes o No, en el que las clases estan bastante desbalanceadas: 83.88% No, 16.12% Yes\n",
        "\n",
        "Hay 8 variables categóricas que hay que codificar.\n",
        "\n",
        "Hay 5 variables que les faltan valores (EnviromentSatisfaction, JobSatisfaction, WorkLifeBalance, NumCompaniesWorked y TotalWorkingYears)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columnas constantes: ['EmployeeCount', 'Over18', 'StandardHours']\n",
            "Columnas ID: ['EmployeeID']\n"
          ]
        }
      ],
      "source": [
        "# 1. Comprobar columnas constantes\n",
        "constantes = [col for col in data.columns if data[col].nunique() == 1]\n",
        "print(\"Columnas constantes:\", constantes)\n",
        "\n",
        "# 2. Comprobar columnas ID\n",
        "columnas_id = [col for col in data.columns if data[col].nunique() == len(data)]\n",
        "print(\"Columnas ID:\", columnas_id)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Como hay 3 columnas que no varían y otra que es un ID, se les elimina del dataframe porque no aportan ninguna información útil\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = data.drop(columns= constantes + columnas_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Despues, vemos todos los valores distintos que tiene las variables categóricas y sus percentiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Categorías para la columna 'BusinessTravel':\n",
            "BusinessTravel\n",
            "Travel_Rarely        70.918367\n",
            "Travel_Frequently    18.775510\n",
            "Non-Travel           10.306122\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "\n",
            "Categorías para la columna 'Department':\n",
            "Department\n",
            "Research & Development    65.782313\n",
            "Sales                     29.965986\n",
            "Human Resources            4.251701\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "\n",
            "Categorías para la columna 'EducationField':\n",
            "EducationField\n",
            "Life Sciences       41.054422\n",
            "Medical             31.972789\n",
            "Marketing           10.612245\n",
            "Technical Degree     9.251701\n",
            "Other                5.238095\n",
            "Human Resources      1.870748\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "\n",
            "Categorías para la columna 'Gender':\n",
            "Gender\n",
            "Male      61.156463\n",
            "Female    38.843537\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "\n",
            "Categorías para la columna 'JobRole':\n",
            "JobRole\n",
            "Sales Executive              21.666667\n",
            "Research Scientist           20.816327\n",
            "Laboratory Technician        17.857143\n",
            "Manufacturing Director        9.829932\n",
            "Healthcare Representative     9.047619\n",
            "Manager                       6.768707\n",
            "Research Director             5.510204\n",
            "Sales Representative          5.272109\n",
            "Human Resources               3.231293\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "\n",
            "Categorías para la columna 'MaritalStatus':\n",
            "MaritalStatus\n",
            "Married     46.530612\n",
            "Single      31.156463\n",
            "Divorced    22.312925\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "\n",
            "Categorías para la columna 'Over18':\n",
            "Over18\n",
            "Y    100.0\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "\n",
            "Categorías para la columna 'Attrition':\n",
            "Attrition\n",
            "No     83.877551\n",
            "Yes    16.122449\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Filtrar las columnas de tipo 'object' (categóricas)\n",
        "categoricos = data.select_dtypes(include=['object']).columns\n",
        "\n",
        "numericos = data.select_dtypes(include=['float64']).columns\n",
        "\n",
        "# Mostrar las categorías y su porcentaje para cada columna categórica\n",
        "for col in categoricos:\n",
        "    print(f\"Categorías para la columna '{col}':\")\n",
        "    print(data[col].value_counts(normalize=True) * 100)  # Multiplicamos por 100 para obtener el porcentaje\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para poder operar con estos datos categóricos hay que codificarlos como One-Hot-Encoding, o de manera ordinal si un atributo tiene algún tipo de cardinalidad.\n",
        "En este caso consideramos que ninguna de los 8 atributos son cardinales por lo que los codificaremos todos con One-Hot-Encoding\n",
        "\n",
        "Primero se dividrirán las categorias en input y output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "X_data = data.drop('Attrition', axis=1)\n",
        "\n",
        "Y_data = data['Attrition']\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers = [\n",
        "                    ('categorical', OneHotEncoder(handle_unknown='ignore'), categoricos),\n",
        "                    ('numerical', MinMaxScaler(), numericos)\n",
        "                   ],\n",
        "                   remainder='passthrough')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "A given column is not a column of the dataframe",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\Guillermo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;31mKeyError\u001b[0m: 'Attrition'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\Guillermo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\__init__.py:505\u001b[0m, in \u001b[0;36m_get_column_indices\u001b[1;34m(X, key)\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns:\n\u001b[1;32m--> 505\u001b[0m     col_idx \u001b[38;5;241m=\u001b[39m \u001b[43mall_columns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    506\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col_idx, numbers\u001b[38;5;241m.\u001b[39mIntegral):\n",
            "File \u001b[1;32mc:\\Users\\Guillermo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
            "\u001b[1;31mKeyError\u001b[0m: 'Attrition'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[25], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m neighbors\n\u001b[1;32m----> 3\u001b[0m \u001b[43mpreprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m X \u001b[38;5;241m=\u001b[39m preprocessor\u001b[38;5;241m.\u001b[39mtransform(X_data)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Notice that now we have 7 columnos\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Guillermo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:860\u001b[0m, in \u001b[0;36mColumnTransformer.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    857\u001b[0m _raise_for_params(params, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    858\u001b[0m \u001b[38;5;66;03m# we use fit_transform to make sure to set sparse_output_ (for which we\u001b[39;00m\n\u001b[0;32m    859\u001b[0m \u001b[38;5;66;03m# need the transformed data) to have consistent output type in predict\u001b[39;00m\n\u001b[1;32m--> 860\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\Guillermo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:295\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 295\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    297\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    298\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    299\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    300\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    301\u001b[0m         )\n",
            "File \u001b[1;32mc:\\Users\\Guillermo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Guillermo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:906\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    903\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_transformers()\n\u001b[0;32m    904\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(X)\n\u001b[1;32m--> 906\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_column_callables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    907\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_remainder(X)\n\u001b[0;32m    909\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _routing_enabled():\n",
            "File \u001b[1;32mc:\\Users\\Guillermo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:496\u001b[0m, in \u001b[0;36mColumnTransformer._validate_column_callables\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    494\u001b[0m         columns \u001b[38;5;241m=\u001b[39m columns(X)\n\u001b[0;32m    495\u001b[0m     all_columns\u001b[38;5;241m.\u001b[39mappend(columns)\n\u001b[1;32m--> 496\u001b[0m     transformer_to_input_indices[name] \u001b[38;5;241m=\u001b[39m \u001b[43m_get_column_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_columns \u001b[38;5;241m=\u001b[39m all_columns\n\u001b[0;32m    499\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transformer_to_input_indices \u001b[38;5;241m=\u001b[39m transformer_to_input_indices\n",
            "File \u001b[1;32mc:\\Users\\Guillermo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\__init__.py:513\u001b[0m, in \u001b[0;36m_get_column_indices\u001b[1;34m(X, key)\u001b[0m\n\u001b[0;32m    510\u001b[0m         column_indices\u001b[38;5;241m.\u001b[39mappend(col_idx)\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 513\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA given column is not a column of the dataframe\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m column_indices\n",
            "\u001b[1;31mValueError\u001b[0m: A given column is not a column of the dataframe"
          ]
        }
      ],
      "source": [
        "from sklearn import neighbors\n",
        "\n",
        "preprocessor.fit(X_data)\n",
        "X = preprocessor.transform(X_data)\n",
        "\n",
        "# Notice that now we have 7 columnos\n",
        "print(X.shape)\n",
        "print()\n",
        "\n",
        "# Notice that now the type of the data matrix is numpy, which can already be used by sklearn\n",
        "print(type(X))\n",
        "print()\n",
        "\"\"\"\n",
        "clf = neighbors.KNeighborsClassifier()\n",
        "\n",
        "# Now, we train (fit) the method on the (X,y) dataset\n",
        "clf.fit(X_data, Y_data)\n",
        "\"\"\"\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
